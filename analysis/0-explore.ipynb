{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Notebook 0 - Exploring Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 0 - Import libraries and basic metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wfdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_dir = os.path.abspath('..')\n",
    "data_dir = os.path.join(base_dir, 'data')\n",
    "\n",
    "# Table of record names and the ground truth labels of their alarms\n",
    "alarms = pd.read_csv(os.path.join(data_dir, 'alarms.csv'),\n",
    "                         dtype={'recordname':object, 'result':bool})\n",
    "\n",
    "# Set the name as the index for the alarm data table\n",
    "alarms.set_index('recordname', inplace=True)\n",
    "# List of record names\n",
    "record_names = list(alarms.index)\n",
    "# Record names with true alarms\n",
    "record_names_true = list(alarms.loc[alarms['result']==True].index)\n",
    "# Record names with false alarms\n",
    "record_names_false = list(alarms.loc[alarms['result']==False].index)\n",
    "    \n",
    "# Distribution of alarm results\n",
    "n_true = len(record_names_true)\n",
    "n_false = len(record_names_false)\n",
    "\n",
    "print('Alarm distribution: %d True, %d False, %d Total' % (n_true, n_false, len(alarms)))\n",
    "display(alarms[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 - Inspect signal content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# All channels can be categorized into ecg, blood pressure, or respiration.\n",
    "# We are not using RESP in this project.\n",
    "ecg_channels = []\n",
    "bp_channels = []\n",
    "\n",
    "for record_name in record_names:\n",
    "    record = wfdb.rdheader(os.path.join(data_dir, record_name))\n",
    "    # First 2 channels are ECGs\n",
    "    ecg_channels.append(record.sig_name[0])\n",
    "    ecg_channels.append(record.sig_name[1])\n",
    "    \n",
    "    # Channel 2 is blood pressure. Channel 3 is either blood pressure or resp.\n",
    "    for ch in range(2, record.n_sig):\n",
    "        if record.sig_name[ch] != 'RESP':\n",
    "            bp_channels.append(record.sig_name[ch])\n",
    "\n",
    "all_channels = ecg_channels + bp_channels\n",
    "channel_frequencies = dict(zip(all_channels,\n",
    "                               [all_channels.count(chan) for chan in all_channels]))\n",
    "\n",
    "ecg_channels = list(set(ecg_channels))\n",
    "bp_channels = list(set(bp_channels))\n",
    "\n",
    "\n",
    "print('ECG channels:', ecg_channels)\n",
    "print('Blood pressure channels:', bp_channels)\n",
    "display('Channel frequencies: ', channel_frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*In this session, we are only going to use channels 0-2*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 - Visualize Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from wfdb import processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# All alarms are triggered within last 10s. Visualize 4:40 to 5:00 - 280 to 300s.\n",
    "def visualize_raw(record_name, start_sec=290, stop_sec=300):\n",
    "    \n",
    "    fs = 250\n",
    "    # Read record\n",
    "    signal, fields = wfdb.rdsamp(os.path.join(data_dir, record_name),\n",
    "                                 sampfrom=start_sec * fs,\n",
    "                                 sampto=stop_sec * fs, channels=[0,1,2])\n",
    "\n",
    "    # Get beat indices\n",
    "    qrs_0 = processing.gqrs_detect(signal[:, 0], fs=fs)\n",
    "    qrs_1 = processing.gqrs_detect(signal[:, 1], fs=fs)\n",
    "    pulse_2 = wfdb.rdann(os.path.join(data_dir, record_name), 'wabp2',\n",
    "                         sampfrom = start_sec * fs,\n",
    "                         sampto=stop_sec * fs, shift_samps=True).sample\n",
    "\n",
    "    beat_inds = [qrs_0, qrs_1, pulse_2]\n",
    "\n",
    "    # Alarm result\n",
    "    result = alarms.loc[record_name, 'result']\n",
    "\n",
    "    if result:\n",
    "        result = 'True Alarm'\n",
    "        style='r'\n",
    "    else:\n",
    "        result = 'False Alarm'\n",
    "        style='b'\n",
    "\n",
    "    wfdb.plot_items(signal=signal, ann_samp=beat_inds, time_units='seconds', fs=fs,\n",
    "                    title='Record: %s %s' % (record_name, result), figsize = (16, 8),\n",
    "                    ylabel=fields['sig_name'], sig_style=style, ann_style=['k*'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record_name in record_names[260:275]:\n",
    "    visualize_raw(record_name, start_sec=280, stop_sec=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Section 3 - Calculate and Visualize Basic Signal Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features to extract for each signal\n",
    "\n",
    "- Statistical moments\n",
    "- Detected beats and derived information\n",
    "  - Number of beats detected\n",
    "  - heart rate\n",
    "- Spectral content\n",
    "  - Relative power ratios of low, medium, high frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.signal import periodogram\n",
    "from scipy.stats import skew, kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Functions for calculating features\n",
    "def calc_moments(data):\n",
    "    \"\"\"\n",
    "    Calculate moments of a 1d feature: mean, std, skew, kurtosis\n",
    "    \"\"\"\n",
    "    data_mean = np.mean(data, axis=0)\n",
    "    data_std = np.std(data, axis=0)\n",
    "    data_skew = skew(data)\n",
    "    data_kurt = kurtosis(data)\n",
    "    \n",
    "    return data_mean, data_std, data_skew, data_kurt\n",
    "\n",
    "def calc_spectral_ratios(signal, fs, f_low=5, f_med=25, f_high=70):\n",
    "    \"\"\"\n",
    "    Return the power ratio contained in 3 bands.\n",
    "    LF (0–5 Hz), MF (5–25 Hz) and HF (30–70 Hz).\n",
    "    \"\"\"\n",
    "    # Calculate power spectrum using periodogram\n",
    "    f, pxx = periodogram(signal, fs)\n",
    "    \n",
    "    # Relative areas\n",
    "    a1 = np.sum(pxx[np.where(f > -1)[0][0]:np.where(f > f_low)[0][0]])\n",
    "    a2 = np.sum(pxx[np.where(f > 5)[0][0]:np.where(f > f_med)[0][0]])\n",
    "    a3 = np.sum(pxx[np.where(f > 25)[0][0]:np.where(f > f_high)[0][0]])\n",
    "    a_total = a1 + a2 + a3\n",
    "    \n",
    "    # If there is no spectral power. ie. signal is flatline.\n",
    "    if a_total == 0:\n",
    "        return 1, 0 ,0\n",
    "    \n",
    "    return a1 / a_total, a2 / a_total, a3 / a_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calc_features(record_name):\n",
    "    \"\"\"\n",
    "    Aggregate function. Calculate all features for the last 10s of a record.\n",
    "    \n",
    "    Features for each signal are:\n",
    "    - Moments: mean, std, skew, kurtosis\n",
    "    - Number of beats detected\n",
    "    - Average heart rate\n",
    "    - Spectral band power ratios\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    record_name : str\n",
    "        The record name\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    features : pandas dataframe\n",
    "        Dataframe of the calculated features\n",
    "\n",
    "    \"\"\"\n",
    "    fs = 250\n",
    "    start_sec = 290\n",
    "    stop_sec = 300\n",
    "    \n",
    "    # Desired features\n",
    "    features = []\n",
    "    # Features are calculated for each individual signal\n",
    "    feature_labels = [['_'.join([moment, str(ch)]) for moment in ['mean', 'std', 'skew',\n",
    "                                                                  'kurt', 'n_beats', 'hr',\n",
    "                                                                  'lfp', 'mfp', 'hfp']] for ch in range(3)]\n",
    "    feature_labels = [x for y in feature_labels for x in y] + ['result']\n",
    "    \n",
    "    # Read record\n",
    "    signal, fields = wfdb.rdsamp(os.path.join(data_dir, record_name),\n",
    "                                 sampfrom=start_sec*fs, sampto=stop_sec*fs,\n",
    "                                 channels=[0, 1, 2])\n",
    "    \n",
    "    # Get beat locations\n",
    "    qrs_0 = processing.xqrs_detect(signal[:, 0], fs=fs, verbose=False)\n",
    "    qrs_1 = processing.xqrs_detect(signal[:, 1], fs=fs, verbose=False)\n",
    "    pulse_2 = wfdb.rdann(os.path.join(data_dir, record_name), 'wabp2',\n",
    "                         sampfrom = start_sec*fs, sampto = stop_sec*fs,\n",
    "                         shift_samps=True).sample\n",
    "    \n",
    "    beat_inds = [qrs_0, qrs_1, pulse_2]\n",
    "    \n",
    "    # Calculate features for each signal\n",
    "    for ch in range(3):\n",
    "        # Moments\n",
    "        features = features + list(calc_moments(signal[:,ch]))\n",
    "        \n",
    "        # Beat information\n",
    "        rr = processing.calc_rr(qrs_locs=beat_inds[ch])\n",
    "        n_beats = len(rr)\n",
    "        hr = processing.calc_mean_hr(rr=rr, fs=fs)\n",
    "        features = features + [n_beats, hr]\n",
    "        \n",
    "        # Frequency information\n",
    "        features = features + list(calc_spectral_ratios(signal[:, ch], fs=fs))\n",
    "        \n",
    "    # Add on the alarm label\n",
    "    features = features + [alarms.loc[record_name]['result']]\n",
    "    # Convert to dataframe\n",
    "    features = pd.DataFrame([features], columns=feature_labels, index=[record_name])\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def visualize_features(features):\n",
    "    \"\"\"\n",
    "    Plot a histogram of each column in a dataframe\n",
    "    \"\"\"\n",
    "    for feature_name in features.columns[:-1]:\n",
    "        feature_true = features.loc[features['result'], feature_name].values\n",
    "        feature_false = features.loc[features['result']==False, feature_name].values\n",
    "\n",
    "        feature_true = feature_true[~np.isnan(feature_true)]\n",
    "        feature_false = feature_false[~np.isnan(feature_false)]\n",
    "\n",
    "        plt.figure(figsize=(16, 8))\n",
    "        plt.grid(True)\n",
    "\n",
    "        n, bins, patches = plt.hist(feature_true, 25, normed=1, facecolor='r', alpha=0.9,)\n",
    "        n, bins, patches = plt.hist(feature_false, 25, normed=1, facecolor='b', alpha=0.75)\n",
    "\n",
    "        plt.title(feature_name)\n",
    "        plt.legend(['True Alarm (%d/%d)' % (len(feature_true), n_true),\n",
    "                    'False Alarm (%d/%d)' % (len(feature_false), n_false)])\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate features for all records using multiple cpus\n",
    "pool = Pool(processes=cpu_count() - 1)\n",
    "features = pool.map(calc_features, record_names)\n",
    "\n",
    "# Combine features into a single data frame\n",
    "features = pd.concat(features)\n",
    "\n",
    "print('Finished calculating features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# The feature design matrix\n",
    "display(features.iloc[260:275])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize the features\n",
    "visualize_features(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect true alarms in particular\n",
    "# It seems that in every true alarm case, both ECGs are valid. We could leverage this fact...\n",
    "for record_name in record_names_true[20:40]:\n",
    "    try:\n",
    "        visualize_raw(record_name, start_sec=290, stop_sec=300)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label some data. This will come in handy later.\n",
    "vtach_intervals = {\n",
    "    'v328s':[293, 296.5],\n",
    "    'v334s':[296.2, 299.5],\n",
    "    'v348s':[294, 300],\n",
    "    'v368s':[290, 293],\n",
    "    'v369l':[296, 300],\n",
    "    'v404s':[292, 300],\n",
    "    'v448s':[294, 299],\n",
    "    'v471l':[298, 300],\n",
    "    'v522s':[291, 299],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
