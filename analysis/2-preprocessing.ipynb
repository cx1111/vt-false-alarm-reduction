{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2 - Preprocessing\n",
    "\n",
    "Before calculating features from the raw signals, we should preprocess:\n",
    "- cleanse data\n",
    "- judge data quality\n",
    "\n",
    "It is very useful to remove unwanted errors and noise, so that we only target our analysis on meaningful information.\n",
    "\n",
    "`\"Garbage in, garbage out\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wfdb\n",
    "from wfdb import processing\n",
    "\n",
    "from vt.records import get_alarms, data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alarms, record_names, record_names_true, record_names_false = get_alarms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 0 - Measuring Flatline and Saturation\n",
    "\n",
    "We do not want to analyze signals that are not accurately measured:\n",
    "\n",
    "- flatline signals, ie. when the lead is disconnected\n",
    "- saturated signals, ie. when the signal calibration leads to values exceeding the input digital range\n",
    "\n",
    "**Goal**: Define quantitative metrics that can measure flatness and saturation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missing_prop(sig):\n",
    "    \"\"\"\n",
    "    Get the proportion of missing values from the signal\n",
    "    \"\"\"\n",
    "    if sig.ndim == 2:\n",
    "        return [get_missing_prop(sig[:, ch]) for ch in range(sig.shape[1])]\n",
    "    \n",
    "    sig_len = len(sig)\n",
    "    nan_locs = np.where(np.isnan(sig))[0]\n",
    "    return nan_locs.size\n",
    "\n",
    "def is_missing(sig, missing_thresh=0.4):\n",
    "    \"\"\"\n",
    "    Determine whether a signal has too many missing values.\n",
    "    Returns True if the ratio of nans exceeds missing_thresh.\n",
    "    \"\"\"\n",
    "    if sig.ndim == 2:\n",
    "        return [is_missing(sig[:, ch], missing_thresh) for ch in range(sig.shape[1])]\n",
    "    \n",
    "    sig_len = len(sig)\n",
    "    missing_prop = get_missing_prop(sig)\n",
    "    \n",
    "    if missing_prop / sig_len > missing_thresh:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def get_mode_prop(sig):\n",
    "    \"\"\"\n",
    "    Get the proportion of samples of the signal equal\n",
    "    to the mode\n",
    "    \"\"\"\n",
    "    if sig.ndim == 2:\n",
    "        return [get_mode_prop(sig[:, ch]) for ch in range(sig.shape[1])]\n",
    "    \n",
    "    return mode(sig).count[0] / len(sig)\n",
    "\n",
    "def is_flatline(sig, mode_thresh=0.8):\n",
    "    \"\"\"\n",
    "    Determine whether a signal is flatline\n",
    "    by inspecting the proportion of samples that\n",
    "    match the mode, or are invalid\n",
    "    \"\"\"\n",
    "    if sig.ndim == 2:\n",
    "        return [is_flatline(sig[:, ch], mode_thresh) for ch in range(sig.shape[1])]\n",
    "    \n",
    "    mode_prop = get_mode_prop(sig)\n",
    "    \n",
    "    if mode_prop / len(sig) > mode_thresh:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def get_edge_prop(sig, n_bins=8):\n",
    "    \"\"\"\n",
    "    Get the proportion of the signal in the max and min bins\n",
    "    \n",
    "    \"\"\"\n",
    "    if sig.ndim == 2:\n",
    "        return [get_edge_prop(sig[:, ch], n_bins) for ch in range(sig.shape[1])]\n",
    "    \n",
    "    # get rid of nans\n",
    "    sig = sig[~np.isnan(sig)]\n",
    "    if sig.size == 0:\n",
    "        return 0\n",
    "    \n",
    "    # Bin the data. Get proportion of values in high and low bins\n",
    "    freq, bin_edges = np.histogram(sig, bins=n_bins)\n",
    "    edge_prop = (freq[0] + freq[-1]) / np.sum(freq)\n",
    "    \n",
    "    return edge_prop\n",
    "\n",
    "def is_saturated(sig, edge_thresh=0.3):\n",
    "    \"\"\"\n",
    "    Determine whether or not a signal is saturated, depending\n",
    "    on whether the proportion of samples in the max/min bins\n",
    "    crosses the threshold.\n",
    "    \"\"\"\n",
    "    if sig.ndim == 2:\n",
    "        return [is_saturated(sig[:, ch], edge_thresh) for ch in range(sig.shape[1])]\n",
    "    \n",
    "    if get_edge_prop(sig) > edge_thresh:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def is_valid(sig, missing_thresh, mode_thresh, edge_thresh):\n",
    "    \"\"\"\n",
    "    Determine whether a signal is valid. It must be neither too:\n",
    "    - empty\n",
    "    - flatlined\n",
    "    - saturated on both sides\n",
    "    \"\"\"\n",
    "    if sig.ndim == 2:\n",
    "        return [is_valid(sig[:, ch], missing_thresh, mode_thresh, edge_thresh) for ch in range(sig.shape[1])]\n",
    "    \n",
    "    if is_missing(sig, missing_thresh) or is_flatline(sig, mode_thresh) or is_saturated(sig, edge_thresh):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 - Visualize performance\n",
    "\n",
    "Visualize metrics and see whether metrics match desired labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_record_quality(record_name, start_sec=290, stop_sec=300):\n",
    "    \"\"\"\n",
    "    Visualize a few 'quality' parameters of a single record.\n",
    "    \n",
    "    \"\"\"\n",
    "    fs = 250\n",
    "    # Read record\n",
    "    signal, fields = wfdb.rdsamp(os.path.join(data_dir, record_name),\n",
    "                                 sampfrom=start_sec*fs, sampto=stop_sec*fs,\n",
    "                                 channels=[0, 1, 2])\n",
    "    \n",
    "    missing_prop = get_missing_prop(signal)\n",
    "    mode_prop = get_mode_prop(signal)\n",
    "    edge_prop = get_edge_prop(signal)\n",
    "    \n",
    "    if alarms.loc[record_name, 'result']:\n",
    "        sig_style = 'r'\n",
    "    else:\n",
    "        sig_style = 'b'\n",
    "\n",
    "    wfdb.plot_items(signal=signal, title='Record %s' % record_name, sig_style=sig_style,\n",
    "                    figsize=(14, 7))\n",
    "    print('missing prop:', missing_prop)\n",
    "    print('mode prop', mode_prop)\n",
    "    print('edge prop', edge_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize signal quality metrics of the last 10s\n",
    "for record_name in record_names[260:275]:\n",
    "    visualize_record_quality(record_name)\n",
    "    print('')\n",
    "    # Seems 10s is too large of a window to use for these aggregate metrics.\n",
    "    # Need to localize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize signal quality metrics of the last 10s, in 5s windows\n",
    "for record_name in record_names[260:275]:\n",
    "    visualize_record_quality(record_name, start_sec=290, stop_sec=295)\n",
    "    visualize_record_quality(record_name, start_sec=295, stop_sec=300)\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems the proportion of values in edge bins does a poor job at picking up saturation.\n",
    "\n",
    "Can you think of something better for any of the situations we are trying to detect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your functions here\n",
    "\n",
    "# def is_saturated():\n",
    "#     pass\n",
    "\n",
    "# def is_flatline():\n",
    "#     pass\n",
    "\n",
    "# def visualize_record_quality(record_name, start_sec=290, stop_sec=300):\n",
    "#     \"\"\"\n",
    "#     Visualize a few 'quality' parameters of a single record.\n",
    "    \n",
    "#     \"\"\"\n",
    "#     fs = 250\n",
    "#     # Read record\n",
    "#     signal, fields = wfdb.rdsamp(os.path.join(data_dir, record_name),\n",
    "#                                  sampfrom=start_sec*fs, sampto=stop_sec*fs,\n",
    "#                                  channels=[0, 1, 2])\n",
    "    \n",
    "#     # Insert features here!!!!!\n",
    "    \n",
    "#     if alarms.loc[record_name, 'result']:\n",
    "#         sig_style = 'r'\n",
    "#     else:\n",
    "#         sig_style = 'b'\n",
    "\n",
    "#     wfdb.plot_items(signal=signal, title='Record %s' % record_name, sig_style=sig_style,\n",
    "#                     figsize=(14, 7))\n",
    "    \n",
    "#     # Print your features here!!!!!\n",
    "#     print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize signal quality metrics of the last 10s, in 5s windows\n",
    "# for record_name in record_names[260:275]:\n",
    "#     visualize_record_quality(record_name, start_sec=290, stop_sec=295)\n",
    "#     visualize_record_quality(record_name, start_sec=295, stop_sec=300)\n",
    "#     print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another possible solution\n",
    "\n",
    "This process is often iterative!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_consec_prop(sig):\n",
    "    \"\"\"\n",
    "    Get the proportion of the signal that shares the same\n",
    "    value as its previous sample.\n",
    "    \n",
    "    \"\"\"\n",
    "    if sig.ndim == 2:\n",
    "        return [get_consec_prop(sig[:, ch]) for ch in range(sig.shape[1])]\n",
    "    \n",
    "    n_consec = len(np.where(np.diff(sig)==0)[0])\n",
    "    consec_prop = n_consec / len(sig)\n",
    "    return consec_prop\n",
    "\n",
    "def is_saturated(sig, consec_thresh=0.01):\n",
    "    \"\"\"\n",
    "    Determine whether or not a signal is saturated, depending\n",
    "    on whether the proportion of consecutive samples\n",
    "    crosses the threshold.\n",
    "    \"\"\"\n",
    "    if sig.ndim == 2:\n",
    "        return [is_saturated(sig[:, ch], edge_thresh) for ch in range(sig.shape[1])]\n",
    "    \n",
    "    if get_consec_prop(sig) > consec_thresh:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def visualize_record_quality(record_name, start_sec=290, stop_sec=300):\n",
    "    \"\"\"\n",
    "    Visualize a few 'quality' parameters of a single record.\n",
    "    \n",
    "    \"\"\"\n",
    "    fs = 250\n",
    "    # Read record\n",
    "    signal, fields = wfdb.rdsamp(os.path.join(data_dir, record_name),\n",
    "                                 sampfrom=start_sec*fs, sampto=stop_sec*fs,\n",
    "                                 channels=[0, 1, 2])\n",
    "    \n",
    "    mode_prop = get_mode_prop(signal)\n",
    "    consec_prop = get_consec_prop(signal)\n",
    "    \n",
    "    if alarms.loc[record_name, 'result']:\n",
    "        sig_style = 'r'\n",
    "    else:\n",
    "        sig_style = 'b'\n",
    "\n",
    "    wfdb.plot_items(signal=signal, title='Record %s' % record_name, sig_style=sig_style,\n",
    "                    figsize=(14, 7))\n",
    "    print('mode prop', mode_prop, 'consec prop', consec_prop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize signal quality metrics of the last 10s, in 5s windows\n",
    "for record_name in record_names[260:275]:\n",
    "    visualize_record_quality(record_name, start_sec=290, stop_sec=295)\n",
    "    visualize_record_quality(record_name, start_sec=295, stop_sec=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The issue is difficult\n",
    "\n",
    "Problems with potential solutions:\n",
    "- Detect saturation\n",
    "  - Using proportion of samples in edge bins: flat one-sided ecgs will have most of their samples in one of the edge bins.\n",
    "  - Using proportion of samples with 0 gradient: low resolution digitization may produce many consecutive samples\n",
    "- Detect flatline\n",
    "  - Using standard deviation: unscaled signals have different amplitude ranges from the expected values\n",
    "  - Using proportion of samples in mode: flatlines may not be *totally* flat. There could be very small sample variations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 - Filling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing(sig):\n",
    "    \"\"\"\n",
    "    Fill missing values of a signal by interpolating between\n",
    "    present samples, and extending the earliest/latest values\n",
    "    forwards/backwards.\n",
    "    \"\"\"\n",
    "    if sig.ndim == 2:\n",
    "        clean_sig = np.empty([sig.shape[0], sig.shape[1]])\n",
    "        for ch in range(sig.shape[1]):\n",
    "            clean_sig[:, ch] = fill_missing(sig=sig[:, ch])\n",
    "        return clean_sig\n",
    "    \n",
    "    sig_len = len(sig)\n",
    "    invalid_inds = np.where(np.isnan(sig))[0]\n",
    "    \n",
    "    n_invalid = invalid_inds.size\n",
    "    \n",
    "    # Return flatline for completely empty signal\n",
    "    if n_invalid == sig_len:\n",
    "        return np.zeros(sig_len)\n",
    "    \n",
    "    if n_invalid:\n",
    "        valid_inds = np.where(~np.isnan(sig))[0]\n",
    "        valid_samps = sig[valid_inds]\n",
    "        # https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.interp1d.html\n",
    "        f = interpolate.interp1d(valid_inds, valid_samps)\n",
    "\n",
    "        clean_sig = sig.copy()\n",
    "\n",
    "        # Set samples on sides of first and last valid samples\n",
    "        # to their values.\n",
    "        if valid_inds[0] != 0:\n",
    "            clean_sig[:valid_inds[0]] = sig[valid_inds[0]]\n",
    "        if valid_inds[-1] != sig_len - 1:\n",
    "            clean_sig[valid_inds[-1] + 1:] = sig[valid_inds[-1]]\n",
    "\n",
    "        invalid_inds = np.where(np.isnan(sig))[0]\n",
    "        invalid_inds = invalid_inds[(invalid_inds > valid_inds[0]) & (invalid_inds < valid_inds[-1])]\n",
    "        # Interpolate between existing samples.\n",
    "        clean_sig[invalid_inds] = f(invalid_inds)\n",
    "    else:\n",
    "        clean_sig = sig\n",
    "    \n",
    "    return clean_sig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3 - Filtering to Removing Noise\n",
    "\n",
    "Remove high and low frequency components of the signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, filtfilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandpass(sig, fs=250, f_low=0.5, f_high=40, order=4):\n",
    "    \"\"\"\n",
    "    Bandpass filter the signal\n",
    "    \"\"\"\n",
    "    if sig.ndim ==2:\n",
    "        sig_filt = np.zeros(sig.shape)\n",
    "        for ch in range(sig.shape[1]):\n",
    "            sig_filt[:, ch] = bandpass(sig[:, ch], fs, f_low, f_high, order)\n",
    "        return sig_filt\n",
    "    \n",
    "    f_nyq = 0.5 * fs\n",
    "    wlow = f_low / f_nyq\n",
    "    whigh = f_high / f_nyq\n",
    "    b, a = butter(order, [wlow, whigh], btype='band')\n",
    "    sig_filt = filtfilt(b, a, sig, axis=0)\n",
    "    \n",
    "    return sig_filt\n",
    "\n",
    "def is_valid(sig, missing_thresh=0.4, mode_thresh=0.8, consec_thresh=0.01):\n",
    "    \"\"\"\n",
    "    Determine whether or not a signal segment is valid.\n",
    "    It is only valid if it is none of the following:\n",
    "    - flatline\n",
    "    - saturated\n",
    "    - has too many missing values\n",
    "\n",
    "    \"\"\"\n",
    "    if sig.ndim == 2:\n",
    "        return [is_valid(sig[:, ch], missing_thresh, mode_thresh, consec_thresh) for ch in range(sig.shape[1])]\n",
    "    \n",
    "    if (is_missing(sig, missing_thresh=missing_thresh)\n",
    "        or is_flatline(sig, mode_thresh=mode_thresh)\n",
    "        or is_saturated(sig, consec_thresh=consec_thresh)):\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_clean(record_name, start_sec=290, stop_sec=300, check_invalid=True):\n",
    "    \n",
    "    fs = 250\n",
    "    # Read record\n",
    "    signal, fields = wfdb.rdsamp(os.path.join(data_dir, record_name),\n",
    "                                 sampfrom=start_sec * fs,\n",
    "                                 sampto=stop_sec * fs, channels=[0,1,2])\n",
    "\n",
    "    if check_invalid:\n",
    "        valid = is_valid(signal)\n",
    "    else:\n",
    "        valid = [True] * 3\n",
    "        \n",
    "    # Get beat indices\n",
    "    qrs_0 = processing.gqrs_detect(signal[:, 0], fs=fs)\n",
    "    qrs_1 = processing.gqrs_detect(signal[:, 1], fs=fs)\n",
    "    pulse_2 = wfdb.rdann(os.path.join(data_dir, record_name), 'wabp2',\n",
    "                             sampfrom = start_sec * fs,\n",
    "                             sampto=stop_sec * fs, shift_samps=True).sample\n",
    "    beat_inds = [qrs_0, qrs_1, pulse_2]\n",
    "    \n",
    "    # Clean the signals\n",
    "    signal = fill_missing(signal)\n",
    "    signal = bandpass(signal, fs=250, f_low=0.5, f_high=30, order=4)\n",
    "    \n",
    "    # Alarm result\n",
    "    result = alarms.loc[record_name, 'result']\n",
    "\n",
    "    # Graph colours\n",
    "    if result:\n",
    "        result = 'True Alarm'\n",
    "        style=['r'] * 3\n",
    "    else:\n",
    "        result = 'False Alarm'\n",
    "        style=['b'] * 3\n",
    "    \n",
    "    for i in range(len(valid)):\n",
    "        if not valid[i]:\n",
    "            style[i] = 'g'\n",
    "\n",
    "    wfdb.plot_items(signal=signal, ann_samp=beat_inds, time_units='seconds', fs=fs,\n",
    "                    title='Record: %s %s' % (record_name, result), figsize = (16, 8),\n",
    "                    ylabel=fields['sig_name'], sig_style=style, ann_style=['k*'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record_name in record_names[260:275]:\n",
    "    visualize_clean(record_name, start_sec=290, stop_sec=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
